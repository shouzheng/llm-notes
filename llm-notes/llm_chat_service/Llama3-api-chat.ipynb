{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed69ffc8-ba84-48c0-a81d-b1a2504a31da",
   "metadata": {},
   "source": [
    "# 使用openai的api请求"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eebf8e-1206-4cc1-867f-11bf1c288991",
   "metadata": {},
   "source": [
    "## 使用非流式的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ba5981-bf33-47cc-8eef-46b87408f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_paths = ['/data1/llm-notes/llm-notes/llm_chat_service',\n",
    "               '/data1/llm-notes/llm-notes/agent_autogen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cadce0b-8afa-4d11-8b93-f8c7606422f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.extend(python_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2164a8-2d25-450b-bb33-674deac354c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat_client import ChatClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fd7020-e333-486f-9fe2-b42ddbba7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ChatClient(api_key='NULL', base_url='http://127.0.0.1:7777/v1',\n",
    "                    model='Meta-Llama-3-8B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2c0813-ae21-4a41-9981-622f6dccc4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 ms, sys: 7.89 ms, total: 21.9 ms\n",
      "Wall time: 1.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 你好！我是你的智能助手，我可以帮助你回答问题、完成任务、提供建议等。有什么问题或需要帮助的事情？请随时问我！ 😊\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "client.chat(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1709761-4a7f-4aff-ab48-320b11b943dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('你好', '你好！很高兴为你提供帮助。有什么问题或需要讨论的主题吗？'),\n",
       " ('你好', '你好！如果你有任何问题、需要咨询的信息或者想要讨论的话题，请随时告诉我，我会尽力为你提供帮助。')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09bbfd6-5e3e-484e-b5d5-66dfc5e87f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(client.predict, chatbot=gr.Chatbot(height=700))\\\n",
    "    .launch(server_name='0.0.0.0', server_port=9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a47e39-db1a-4b99-9d01-dec3ba1aba7f",
   "metadata": {},
   "source": [
    "## 使用流式的\n",
    "\n",
    "暂时不支持流式的，所以下面的代码无法工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7676af51-7de6-496b-a5fb-8cc53eddada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"Qwen1.5-14B-Chat-GPTQ-Int4\", # 不能不设置，也不能为空\n",
    "    base_url=\"http://127.0.0.1:7777/v1\"\n",
    ")\n",
    "\n",
    "system_prompt = \"你是 Qwen1.5, Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. 你擅长中文和英文的对话。你会为用户提供安全，有帮助，准确的回答。\"\n",
    "\n",
    "def predict(message, history):\n",
    "    history_openai_format = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}\n",
    "    ]\n",
    "    for human, assistant in history:\n",
    "        history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
    "        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
    "    history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
    "  \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"Qwen1.5-14B-Chat-GPTQ-Int4\",\n",
    "        messages=history_openai_format,\n",
    "        temperature=0.3,\n",
    "        stream=True)\n",
    "\n",
    "    partial_message = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            partial_message = partial_message + chunk.choices[0].delta.content\n",
    "            yield partial_message\n",
    "\n",
    "    \n",
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(predict, chatbot=gr.Chatbot(height=700)).launch(server_name='0.0.0.0', server_port=9999)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a417e92b-6e6b-4b96-a8cb-7278b2d3d57d",
   "metadata": {},
   "source": [
    "# 归档"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd93725-ad94-4544-bbd3-f54262ab57c5",
   "metadata": {},
   "source": [
    "## 使用http请求\n",
    "\n",
    "当时因为base_url填写了完整接口的url，导致openai的api请求方案不成功，所以写了下面的方案。\n",
    "\n",
    "目前openai的api方案已经调通，下面的方案可以归档了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e83a09-3246-433f-baa7-2498fcf5707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "\n",
    "def call_llm(message, llm_url=\"http://127.0.0.1:7777/v1/chat/completions\"):\n",
    "    # url = \"http://10.113.73.32:50053/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = json.dumps({\"model\": \"Qwen1.5-14B-Chat-GPTQ-Int4\", \"top_k\": 5, \"top_p\": 0.85, \"temperature\": 0.3,\n",
    "                       \"messages\": message})\n",
    "    s = requests.Session()\n",
    "    s.mount('http://', HTTPAdapter(max_retries=3))\n",
    "    # res = requests.post(url, data=data, headers=headers)\n",
    "    try:\n",
    "        res = s.post(llm_url, data=data, headers=headers, timeout=600)\n",
    "        print(res)\n",
    "        if res.status_code == 200:\n",
    "            return res.json()['choices'][0]['message']['content']\n",
    "        else:\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "system_prompt = \"你是 Qwen1.5, Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. 你擅长中文和英文的对话。你会为用户提供安全，有帮助，准确的回答。\"\n",
    "\n",
    "def predict(message, history):\n",
    "    history_openai_format = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}\n",
    "    ]\n",
    "    for human, assistant in history:\n",
    "        history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
    "        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
    "    history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    return call_llm(history_openai_format)\n",
    "    \n",
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(predict, chatbot=gr.Chatbot(height=700)).launch(server_name='0.0.0.0', server_port=9999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c99357-0722-42d8-a5b8-c99b7eb8d654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
