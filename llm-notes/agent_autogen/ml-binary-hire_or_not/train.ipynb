{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba770b-7b2c-45f4-ba49-2e9eaf4b52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    'model': 'Meta-Llama-3-8B-Instruct',\n",
    "    'base_url': 'http://127.0.0.1:7777/v1',\n",
    "    'api_type': 'open_ai',\n",
    "    'api_key': 'NULL'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7821a31a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "\n",
    "code_execution_config_list = [\n",
    "    {  # 没有保存临时代码\n",
    "        \"work_dir\": \"output\",\n",
    "        \"use_docker\": False\n",
    "    },\n",
    "    {  # 可以保存临时代码\n",
    "        \"executor\": LocalCommandLineCodeExecutor(work_dir=\"output\")\n",
    "    }\n",
    "]\n",
    "\n",
    "code_execution_config = code_execution_config_list[1] # 可以尝试使用不同的code_execution设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99960963-3ebb-4dda-9b19-bfb1e2da72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "# create an AssistantAgent instance named \"assistant\" with the LLM configuration.\n",
    "assistant = AssistantAgent(name=\"assistant\",\n",
    "                           llm_config=llm_config)\n",
    "\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = UserProxyAgent(name=\"user_proxy\",\n",
    "                            human_input_mode=\"NEVER\",\n",
    "                            max_consecutive_auto_reply=10,\n",
    "                            is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "                            code_execution_config=code_execution_config,\n",
    "                            llm_config=llm_config\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437dd4a0-c24a-4d40-9bcd-40bfc28af99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_message_generator():\n",
    "    # your CSV file\n",
    "    file_name = \"PastHires.csv\"\n",
    "    try:\n",
    "        with open(file_name, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "            file_content = file.read()\n",
    "    except FileNotFoundError:\n",
    "        file_content = \"No data found.\"\n",
    "    return \"Data: \\n\" + file_content\n",
    "\n",
    "task = \"\"\"\n",
    "Train a binary-classification model to predict whether a candidate will be hired or not.\n",
    "after train the model success, save the trained model in a new directory named model-{time} and {time} is a placeholder. give the accuracy metric for the trained model by a validation dataset.\n",
    "The data file is PastHires.csv, if you cannot find it, try ../PastHires.csv. The label column is Hired.\n",
    "\n",
    "Important Notes:\n",
    "- Do not issue commands for 'pip install' or 'pip uninstall'. If there is a dependency missing, proactively terminate the session and instruct the user to handle the dependency installation manually.\n",
    "- Ensure that complete code is always provided! even if parts of it have been provided before! For example, code cannot includes phrases such as \"rest of the code remains the same\"!\n",
    "- Ensure that each response generates at most one code block!\n",
    "\"\"\" + my_message_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25775bec-9bdd-4b5a-b733-960b72dac74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the assistant receives a message from the user, which contains the task description\n",
    "chat_res = user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=task,\n",
    "    summary_method=\"reflection_with_llm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a9540-786c-4fa0-915c-d74e8dc27d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8ea4d-6885-4ee9-a3ec-a37355224885",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_res.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33165fb-4936-4058-9b44-0460beb303d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
